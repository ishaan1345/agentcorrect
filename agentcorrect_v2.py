#!/usr/bin/env python3
"""
AgentCorrect V2: The REAL Implementation
Captures and prevents actual AI agent rework in production systems
"""

import json
import time
import hashlib
import sqlite3
import re
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from collections import defaultdict
from difflib import SequenceMatcher
import threading
from pathlib import Path

# ============= CORE DATA STRUCTURES =============

@dataclass
class AgentAction:
    """Represents any action an AI agent takes"""
    action_id: str
    action_type: str  # api_call, db_query, ticket_create, email_draft, etc.
    agent_name: str  # gpt-4, claude, zendesk-ai, etc.
    payload: Dict[str, Any]
    context: Dict[str, Any]
    timestamp: datetime
    
@dataclass
class HumanCorrection:
    """Represents a human fixing an AI agent's output"""
    correction_id: str
    action_id: str  # Links to original AgentAction
    original: Dict[str, Any]
    corrected: Dict[str, Any]
    correction_type: str  # text_edit, field_change, routing_fix, etc.
    user_id: str
    timestamp: datetime
    
@dataclass
class CorrectionPattern:
    """A learned pattern from repeated corrections"""
    pattern_id: str
    pattern_type: str  # tone_adjustment, field_addition, routing_rule, etc.
    condition: Dict[str, Any]  # When to apply
    transformation: Dict[str, Any]  # What to change
    confidence: float
    occurrence_count: int
    success_count: int
    examples: List[Tuple[Dict, Dict]]  # Original ‚Üí Corrected examples

# ============= UI CAPTURE SYSTEM =============

class UICapture:
    """Captures corrections from actual UI interactions"""
    
    def __init__(self):
        self.observers = []
        self.capture_buffer = []
        
    def inject_javascript(self) -> str:
        """JavaScript to inject into any web app to capture corrections"""
        return """
        // AgentCorrect UI Capture Script
        (function() {
            const AGENT_SIGNATURES = [
                'ai-generated',
                'suggested-reply',
                'auto-draft',
                'bot-message',
                /Generated by .*(GPT|Claude|AI)/i,
                /\\[AI\\]/,
            ];
            
            function isAgentGenerated(element) {
                // Check classes
                const classes = element.className || '';
                if (AGENT_SIGNATURES.some(sig => classes.includes(sig))) return true;
                
                // Check data attributes
                if (element.dataset.source === 'ai' || element.dataset.generated) return true;
                
                // Check content patterns
                const content = element.textContent || '';
                if (AGENT_SIGNATURES.some(sig => sig.test && sig.test(content))) return true;
                
                // Check parent context
                const parent = element.closest('[data-composer], [data-editor], .message-draft');
                return parent && parent.querySelector('.ai-indicator, .bot-label');
            }
            
            function captureCorrection(element, originalContent, newContent) {
                // Detect what changed
                const correction = {
                    timestamp: new Date().toISOString(),
                    url: window.location.href,
                    app: detectApp(),  // Zendesk, Intercom, etc.
                    element_type: element.tagName,
                    element_id: element.id,
                    original: originalContent,
                    corrected: newContent,
                    context: {
                        page_title: document.title,
                        user_role: detectUserRole(),
                        ticket_id: extractTicketId(),
                        conversation_id: extractConversationId()
                    }
                };
                
                // Send to AgentCorrect
                sendCorrection(correction);
            }
            
            function detectApp() {
                const hostname = window.location.hostname;
                if (hostname.includes('zendesk')) return 'zendesk';
                if (hostname.includes('intercom')) return 'intercom';
                if (hostname.includes('salesforce')) return 'salesforce';
                if (hostname.includes('servicenow')) return 'servicenow';
                if (hostname.includes('hubspot')) return 'hubspot';
                if (hostname.includes('freshdesk')) return 'freshdesk';
                return 'unknown';
            }
            
            function detectUserRole() {
                // Look for role indicators in the UI
                const roleElement = document.querySelector('[data-user-role], .user-role, .current-user');
                return roleElement ? roleElement.textContent : 'agent';
            }
            
            function extractTicketId() {
                // Common patterns for ticket IDs
                const patterns = [
                    /ticket[/#]?(\\d+)/i,
                    /case[/#]?(\\d+)/i,
                    /issue[/#]?(\\d+)/i,
                    /#(\\d{4,})/
                ];
                
                const url = window.location.href;
                for (const pattern of patterns) {
                    const match = url.match(pattern);
                    if (match) return match[1];
                }
                return null;
            }
            
            function extractConversationId() {
                // Look in URL or DOM
                const urlMatch = window.location.href.match(/conversation[s]?[/#]?([a-z0-9-]+)/i);
                if (urlMatch) return urlMatch[1];
                
                const convElement = document.querySelector('[data-conversation-id]');
                return convElement ? convElement.dataset.conversationId : null;
            }
            
            function sendCorrection(correction) {
                // Send to local extension or remote API
                if (window.agentCorrectExtension) {
                    window.agentCorrectExtension.capture(correction);
                } else {
                    fetch('http://localhost:8888/capture', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify(correction),
                        mode: 'no-cors'
                    }).catch(() => {
                        // Store locally if can't send
                        localStorage.setItem(
                            `agentcorrect_${Date.now()}`,
                            JSON.stringify(correction)
                        );
                    });
                }
            }
            
            // Monitor all text inputs and textareas
            function monitorElement(element) {
                if (!element._agentCorrectMonitored) {
                    element._agentCorrectMonitored = true;
                    
                    let originalContent = null;
                    
                    element.addEventListener('focus', () => {
                        if (isAgentGenerated(element)) {
                            originalContent = element.value || element.textContent;
                        }
                    });
                    
                    element.addEventListener('blur', () => {
                        if (originalContent) {
                            const newContent = element.value || element.textContent;
                            if (newContent !== originalContent) {
                                captureCorrection(element, originalContent, newContent);
                            }
                            originalContent = null;
                        }
                    });
                }
            }
            
            // Monitor DOM for new elements
            const observer = new MutationObserver((mutations) => {
                mutations.forEach(mutation => {
                    mutation.addedNodes.forEach(node => {
                        if (node.nodeType === 1) {  // Element node
                            // Check if it's an input area
                            if (node.matches && node.matches('input, textarea, [contenteditable]')) {
                                monitorElement(node);
                            }
                            // Check children
                            const inputs = node.querySelectorAll('input, textarea, [contenteditable]');
                            inputs.forEach(monitorElement);
                        }
                    });
                });
            });
            
            // Start observing
            observer.observe(document.body, {
                childList: true,
                subtree: true
            });
            
            // Monitor existing elements
            document.querySelectorAll('input, textarea, [contenteditable]').forEach(monitorElement);
            
            console.log('AgentCorrect UI Capture initialized');
        })();
        """
    
    def capture_from_api(self, request_data: dict) -> HumanCorrection:
        """Process correction captured from UI"""
        
        # Generate IDs
        correction_id = hashlib.md5(
            f"{request_data['timestamp']}_{request_data['original']}".encode()
        ).hexdigest()[:16]
        
        action_id = hashlib.md5(
            f"{request_data['url']}_{request_data['original']}".encode()
        ).hexdigest()[:16]
        
        return HumanCorrection(
            correction_id=correction_id,
            action_id=action_id,
            original=self._parse_content(request_data['original']),
            corrected=self._parse_content(request_data['corrected']),
            correction_type=self._detect_correction_type(
                request_data['original'],
                request_data['corrected']
            ),
            user_id=request_data['context'].get('user_role', 'unknown'),
            timestamp=datetime.fromisoformat(request_data['timestamp'].replace('Z', '+00:00'))
        )
    
    def _parse_content(self, content: Any) -> Dict[str, Any]:
        """Parse content into structured format"""
        if isinstance(content, dict):
            return content
        
        if isinstance(content, str):
            # Try to parse as JSON
            try:
                return json.loads(content)
            except:
                # Return as text content
                return {"text": content, "type": "plain_text"}
        
        return {"raw": content}
    
    def _detect_correction_type(self, original: Any, corrected: Any) -> str:
        """Detect what type of correction was made"""
        
        if isinstance(original, str) and isinstance(corrected, str):
            # Text corrections
            orig_lower = original.lower()
            corr_lower = corrected.lower()
            
            # Tone changes
            if "understand your frustration" in orig_lower and "help" in corr_lower:
                return "tone_professional"
            if "best regards" in orig_lower and "cheers" in corr_lower:
                return "tone_casual"
            
            # Content additions
            if len(corrected) > len(original) * 1.2:
                return "content_addition"
            
            # Grammar/spelling
            if SequenceMatcher(None, orig_lower, corr_lower).ratio() > 0.9:
                return "minor_edit"
            
            return "text_rewrite"
        
        if isinstance(original, dict) and isinstance(corrected, dict):
            # Structural changes
            added_keys = set(corrected.keys()) - set(original.keys())
            removed_keys = set(original.keys()) - set(corrected.keys())
            
            if added_keys:
                if "idempotency_key" in added_keys:
                    return "safety_addition"
                if "priority" in added_keys:
                    return "metadata_addition"
                return "field_addition"
            
            if "team" in corrected and original.get("team") != corrected.get("team"):
                return "routing_change"
            
            if "priority" in corrected and original.get("priority") != corrected.get("priority"):
                return "priority_change"
            
            return "field_modification"
        
        return "unknown"

# ============= PATTERN DETECTION ENGINE =============

class PatternDetector:
    """Detects patterns in human corrections"""
    
    def __init__(self):
        self.patterns = {}
        self.min_occurrences = 3  # Need 3+ similar corrections to create pattern
        
    def analyze_corrections(self, corrections: List[HumanCorrection]) -> List[CorrectionPattern]:
        """Find patterns in corrections"""
        
        # Group corrections by type
        grouped = defaultdict(list)
        for correction in corrections:
            grouped[correction.correction_type].append(correction)
        
        patterns = []
        
        for correction_type, group in grouped.items():
            if len(group) >= self.min_occurrences:
                pattern = self._extract_pattern(correction_type, group)
                if pattern:
                    patterns.append(pattern)
        
        return patterns
    
    def _extract_pattern(self, correction_type: str, corrections: List[HumanCorrection]) -> Optional[CorrectionPattern]:
        """Extract a reusable pattern from similar corrections"""
        
        if correction_type == "tone_professional":
            return self._extract_tone_pattern(corrections)
        elif correction_type == "field_addition":
            return self._extract_field_pattern(corrections)
        elif correction_type == "routing_change":
            return self._extract_routing_pattern(corrections)
        elif correction_type == "priority_change":
            return self._extract_priority_pattern(corrections)
        else:
            return self._extract_generic_pattern(correction_type, corrections)
    
    def _extract_tone_pattern(self, corrections: List[HumanCorrection]) -> CorrectionPattern:
        """Extract tone adjustment patterns"""
        
        # Find common phrase replacements
        replacements = {}
        for corr in corrections:
            orig_text = corr.original.get("text", "")
            corr_text = corr.corrected.get("text", "")
            
            # Find what was replaced
            for orig_phrase in ["I understand your frustration", "We apologize for", "Unfortunately"]:
                if orig_phrase.lower() in orig_text.lower():
                    # Find corresponding phrase in corrected
                    replacements[orig_phrase] = self._find_replacement(orig_text, corr_text, orig_phrase)
        
        return CorrectionPattern(
            pattern_id=hashlib.md5(f"tone_pattern_{time.time()}".encode()).hexdigest()[:16],
            pattern_type="tone_adjustment",
            condition={"text_contains": list(replacements.keys())},
            transformation={"replacements": replacements},
            confidence=0.8,
            occurrence_count=len(corrections),
            success_count=0,
            examples=[(c.original, c.corrected) for c in corrections[:3]]
        )
    
    def _extract_field_pattern(self, corrections: List[HumanCorrection]) -> CorrectionPattern:
        """Extract field addition patterns"""
        
        # Find commonly added fields
        added_fields = defaultdict(list)
        for corr in corrections:
            orig_keys = set(corr.original.keys())
            corr_keys = set(corr.corrected.keys())
            
            for added_key in (corr_keys - orig_keys):
                added_fields[added_key].append(corr.corrected[added_key])
        
        # Find most common addition
        if added_fields:
            most_common_field = max(added_fields.keys(), key=lambda k: len(added_fields[k]))
            
            # Determine condition for when to add this field
            condition = self._determine_condition(corrections, most_common_field)
            
            return CorrectionPattern(
                pattern_id=hashlib.md5(f"field_pattern_{most_common_field}_{time.time()}".encode()).hexdigest()[:16],
                pattern_type="field_addition",
                condition=condition,
                transformation={
                    "add_field": most_common_field,
                    "field_value": self._determine_field_value(added_fields[most_common_field])
                },
                confidence=0.85,
                occurrence_count=len(corrections),
                success_count=0,
                examples=[(c.original, c.corrected) for c in corrections[:3]]
            )
        
        return None
    
    def _extract_routing_pattern(self, corrections: List[HumanCorrection]) -> CorrectionPattern:
        """Extract routing correction patterns"""
        
        routing_rules = defaultdict(lambda: defaultdict(int))
        
        for corr in corrections:
            orig_team = corr.original.get("team", "unknown")
            corr_team = corr.corrected.get("team", "unknown")
            
            # Look for conditions that predict routing
            category = corr.original.get("category", "unknown")
            routing_rules[category][(orig_team, corr_team)] += 1
        
        # Find strongest pattern
        best_pattern = None
        best_count = 0
        
        for category, routes in routing_rules.items():
            for (orig, corr), count in routes.items():
                if count > best_count:
                    best_pattern = (category, orig, corr)
                    best_count = count
        
        if best_pattern:
            category, orig_team, corr_team = best_pattern
            
            return CorrectionPattern(
                pattern_id=hashlib.md5(f"routing_{category}_{orig_team}_{corr_team}".encode()).hexdigest()[:16],
                pattern_type="routing_correction",
                condition={
                    "category": category,
                    "team": orig_team
                },
                transformation={
                    "set_team": corr_team
                },
                confidence=best_count / len(corrections),
                occurrence_count=len(corrections),
                success_count=0,
                examples=[(c.original, c.corrected) for c in corrections[:3]]
            )
        
        return None
    
    def _extract_priority_pattern(self, corrections: List[HumanCorrection]) -> CorrectionPattern:
        """Extract priority adjustment patterns"""
        
        priority_rules = []
        
        for corr in corrections:
            orig_priority = corr.original.get("priority", "normal")
            corr_priority = corr.corrected.get("priority", "normal")
            
            if orig_priority != corr_priority:
                # Look for triggers
                text = str(corr.original.get("description", "")) + str(corr.original.get("title", ""))
                
                keywords = self._extract_keywords(text)
                priority_rules.append({
                    "keywords": keywords,
                    "from_priority": orig_priority,
                    "to_priority": corr_priority
                })
        
        # Find common keywords that trigger priority changes
        common_keywords = self._find_common_keywords(priority_rules)
        
        if common_keywords:
            return CorrectionPattern(
                pattern_id=hashlib.md5(f"priority_pattern_{time.time()}".encode()).hexdigest()[:16],
                pattern_type="priority_adjustment",
                condition={
                    "keywords_present": common_keywords,
                    "current_priority": priority_rules[0]["from_priority"]
                },
                transformation={
                    "set_priority": priority_rules[0]["to_priority"]
                },
                confidence=0.75,
                occurrence_count=len(corrections),
                success_count=0,
                examples=[(c.original, c.corrected) for c in corrections[:3]]
            )
        
        return None
    
    def _extract_generic_pattern(self, correction_type: str, corrections: List[HumanCorrection]) -> CorrectionPattern:
        """Extract generic patterns for any correction type"""
        
        # Find commonalities
        common_changes = []
        
        for corr in corrections:
            changes = self._diff_objects(corr.original, corr.corrected)
            common_changes.append(changes)
        
        # Find most common change
        if common_changes:
            return CorrectionPattern(
                pattern_id=hashlib.md5(f"generic_{correction_type}_{time.time()}".encode()).hexdigest()[:16],
                pattern_type=correction_type,
                condition={"correction_type": correction_type},
                transformation={"changes": common_changes[0]},  # Simplified
                confidence=0.6,
                occurrence_count=len(corrections),
                success_count=0,
                examples=[(c.original, c.corrected) for c in corrections[:3]]
            )
        
        return None
    
    def _find_replacement(self, original: str, corrected: str, phrase: str) -> str:
        """Find what phrase was replaced with"""
        # Simplified - in production would use better text alignment
        orig_pos = original.lower().find(phrase.lower())
        if orig_pos >= 0:
            # Find corresponding position in corrected text
            before = original[:orig_pos]
            after = original[orig_pos + len(phrase):]
            
            # Find similar boundaries in corrected
            corr_start = len(before)
            corr_end = len(corrected) - len(after)
            
            if corr_end > corr_start:
                return corrected[corr_start:corr_end]
        
        return corrected[:50]  # Default to beginning
    
    def _determine_condition(self, corrections: List[HumanCorrection], field: str) -> Dict[str, Any]:
        """Determine when to apply a correction"""
        
        # Look for common patterns in originals that got this field added
        conditions = []
        
        for corr in corrections:
            if field == "idempotency_key":
                # Check for payment-related fields
                if any(key in corr.original for key in ["amount", "payment", "charge", "transaction"]):
                    conditions.append({"has_payment_fields": True})
            elif field == "limit":
                # Check for SQL queries
                if "query" in corr.original or "sql" in corr.original:
                    conditions.append({"has_sql_query": True})
        
        # Return most common condition
        if conditions:
            return conditions[0]
        
        return {"always": True}
    
    def _determine_field_value(self, values: List[Any]) -> Any:
        """Determine what value to use for added field"""
        
        # If all same, use that
        if len(set(str(v) for v in values)) == 1:
            return values[0]
        
        # If UUIDs/timestamps, return generator
        if all(isinstance(v, str) and len(v) > 20 for v in values):
            return {"generate": "uuid"}
        
        # Default
        return values[0] if values else None
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extract important keywords from text"""
        important_words = ["urgent", "critical", "down", "broken", "emergency", "asap", "production", "customer"]
        
        text_lower = text.lower()
        found = []
        
        for word in important_words:
            if word in text_lower:
                found.append(word)
        
        return found
    
    def _find_common_keywords(self, rules: List[Dict]) -> List[str]:
        """Find keywords common across multiple rules"""
        all_keywords = []
        for rule in rules:
            all_keywords.extend(rule["keywords"])
        
        # Find keywords that appear in >50% of rules
        keyword_counts = defaultdict(int)
        for kw in all_keywords:
            keyword_counts[kw] += 1
        
        threshold = len(rules) * 0.5
        common = [kw for kw, count in keyword_counts.items() if count >= threshold]
        
        return common
    
    def _diff_objects(self, obj1: Any, obj2: Any) -> Dict[str, Any]:
        """Find differences between two objects"""
        if isinstance(obj1, dict) and isinstance(obj2, dict):
            changes = {}
            
            # Added keys
            for key in set(obj2.keys()) - set(obj1.keys()):
                changes[f"add_{key}"] = obj2[key]
            
            # Removed keys
            for key in set(obj1.keys()) - set(obj2.keys()):
                changes[f"remove_{key}"] = True
            
            # Changed values
            for key in set(obj1.keys()) & set(obj2.keys()):
                if obj1[key] != obj2[key]:
                    changes[f"change_{key}"] = {"from": obj1[key], "to": obj2[key]}
            
            return changes
        
        return {"change": {"from": obj1, "to": obj2}}

# ============= INTERCEPTION LAYER =============

class AgentInterceptor:
    """Intercepts agent actions and applies corrections"""
    
    def __init__(self, pattern_engine: PatternDetector):
        self.pattern_engine = pattern_engine
        self.patterns = []
        self.stats = defaultdict(int)
        
    def intercept(self, action: AgentAction) -> Dict[str, Any]:
        """Intercept and correct agent action before execution"""
        
        corrected = action.payload.copy()
        applied_patterns = []
        
        for pattern in self.patterns:
            if self._matches_condition(corrected, pattern.condition):
                corrected = self._apply_transformation(corrected, pattern.transformation)
                applied_patterns.append(pattern.pattern_id)
                pattern.success_count += 1
                self.stats["corrections_applied"] += 1
        
        if applied_patterns:
            print(f"‚úÖ Applied {len(applied_patterns)} corrections to {action.agent_name} action")
            self.stats["actions_corrected"] += 1
        
        return corrected
    
    def _matches_condition(self, payload: Dict[str, Any], condition: Dict[str, Any]) -> bool:
        """Check if condition matches payload"""
        
        if "always" in condition:
            return True
        
        if "has_payment_fields" in condition:
            payment_fields = ["amount", "payment", "charge", "price", "total"]
            return any(field in payload for field in payment_fields)
        
        if "has_sql_query" in condition:
            return "query" in payload or "sql" in payload
        
        if "category" in condition:
            return payload.get("category") == condition["category"]
        
        if "team" in condition:
            return payload.get("team") == condition["team"]
        
        if "keywords_present" in condition:
            text = str(payload)
            return any(kw in text.lower() for kw in condition["keywords_present"])
        
        if "text_contains" in condition:
            text = payload.get("text", "") if isinstance(payload, dict) else str(payload)
            return any(phrase.lower() in text.lower() for phrase in condition["text_contains"])
        
        return False
    
    def _apply_transformation(self, payload: Dict[str, Any], transformation: Dict[str, Any]) -> Dict[str, Any]:
        """Apply transformation to payload"""
        
        result = payload.copy()
        
        if "add_field" in transformation:
            field = transformation["add_field"]
            value = transformation["field_value"]
            
            if isinstance(value, dict) and "generate" in value:
                if value["generate"] == "uuid":
                    import uuid
                    result[field] = str(uuid.uuid4())
            else:
                result[field] = value
        
        if "set_team" in transformation:
            result["team"] = transformation["set_team"]
        
        if "set_priority" in transformation:
            result["priority"] = transformation["set_priority"]
        
        if "replacements" in transformation:
            if "text" in result:
                text = result["text"]
                for old, new in transformation["replacements"].items():
                    text = text.replace(old, new)
                result["text"] = text
        
        if "changes" in transformation:
            for change_key, change_val in transformation["changes"].items():
                if change_key.startswith("add_"):
                    key = change_key[4:]
                    result[key] = change_val
                elif change_key.startswith("remove_"):
                    key = change_key[7:]
                    result.pop(key, None)
                elif change_key.startswith("change_"):
                    key = change_key[7:]
                    if isinstance(change_val, dict) and "to" in change_val:
                        result[key] = change_val["to"]
        
        return result
    
    def add_pattern(self, pattern: CorrectionPattern):
        """Add a new pattern to apply"""
        self.patterns.append(pattern)
        print(f"üìö Learned new pattern: {pattern.pattern_type} (confidence: {pattern.confidence:.0%})")
    
    def get_stats(self) -> Dict[str, int]:
        """Get interception statistics"""
        return dict(self.stats)

# ============= MAIN AGENTCORRECT SYSTEM =============

class AgentCorrectV2:
    """The complete AgentCorrect system"""
    
    def __init__(self, db_path: str = ".agentcorrect/v2.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(exist_ok=True)
        
        self.ui_capture = UICapture()
        self.pattern_detector = PatternDetector()
        self.interceptor = AgentInterceptor(self.pattern_detector)
        
        self._init_database()
        self._load_patterns()
        
        print("üöÄ AgentCorrect V2 initialized")
        print(f"üìç Monitoring for corrections at http://localhost:8888/capture")
    
    def _init_database(self):
        """Initialize database for storing corrections and patterns"""
        
        conn = sqlite3.connect(str(self.db_path))
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS corrections (
                correction_id TEXT PRIMARY KEY,
                action_id TEXT,
                original TEXT,
                corrected TEXT,
                correction_type TEXT,
                user_id TEXT,
                timestamp TIMESTAMP
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS patterns (
                pattern_id TEXT PRIMARY KEY,
                pattern_type TEXT,
                condition TEXT,
                transformation TEXT,
                confidence REAL,
                occurrence_count INTEGER,
                success_count INTEGER,
                examples TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.commit()
        conn.close()
    
    def _load_patterns(self):
        """Load existing patterns from database"""
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM patterns ORDER BY confidence DESC")
        
        for row in cursor.fetchall():
            pattern = CorrectionPattern(
                pattern_id=row[0],
                pattern_type=row[1],
                condition=json.loads(row[2]),
                transformation=json.loads(row[3]),
                confidence=row[4],
                occurrence_count=row[5],
                success_count=row[6],
                examples=json.loads(row[7])
            )
            self.interceptor.add_pattern(pattern)
        
        conn.close()
        
        print(f"üìñ Loaded {len(self.interceptor.patterns)} existing patterns")
    
    def capture_correction(self, correction_data: dict):
        """Capture a correction from UI"""
        
        correction = self.ui_capture.capture_from_api(correction_data)
        
        # Store in database
        conn = sqlite3.connect(str(self.db_path))
        conn.execute("""
            INSERT INTO corrections VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            correction.correction_id,
            correction.action_id,
            json.dumps(correction.original),
            json.dumps(correction.corrected),
            correction.correction_type,
            correction.user_id,
            correction.timestamp.isoformat() if isinstance(correction.timestamp, datetime) else correction.timestamp
        ))
        conn.commit()
        
        print(f"üìù Captured {correction.correction_type} correction")
        
        # Check if we can learn a pattern
        self._check_for_patterns(conn)
        
        conn.close()
    
    def _check_for_patterns(self, conn):
        """Check if we have enough corrections to learn a pattern"""
        
        # Get recent corrections
        cursor = conn.cursor()
        cursor.execute("""
            SELECT * FROM corrections
            ORDER BY timestamp DESC
            LIMIT 100
        """)
        
        corrections = []
        for row in cursor.fetchall():
            corrections.append(HumanCorrection(
                correction_id=row[0],
                action_id=row[1],
                original=json.loads(row[2]),
                corrected=json.loads(row[3]),
                correction_type=row[4],
                user_id=row[5],
                timestamp=row[6]
            ))
        
        # Detect patterns
        new_patterns = self.pattern_detector.analyze_corrections(corrections)
        
        for pattern in new_patterns:
            # Check if pattern already exists
            cursor.execute(
                "SELECT pattern_id FROM patterns WHERE pattern_id = ?",
                (pattern.pattern_id,)
            )
            
            if not cursor.fetchone():
                # Save new pattern
                conn.execute("""
                    INSERT INTO patterns VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
                """, (
                    pattern.pattern_id,
                    pattern.pattern_type,
                    json.dumps(pattern.condition),
                    json.dumps(pattern.transformation),
                    pattern.confidence,
                    pattern.occurrence_count,
                    pattern.success_count,
                    json.dumps(pattern.examples)
                ))
                conn.commit()
                
                # Add to interceptor
                self.interceptor.add_pattern(pattern)
    
    def intercept_action(self, agent_name: str, action_type: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Intercept and correct an agent action"""
        
        action = AgentAction(
            action_id=hashlib.md5(f"{agent_name}_{time.time()}".encode()).hexdigest()[:16],
            action_type=action_type,
            agent_name=agent_name,
            payload=payload,
            context={},
            timestamp=datetime.now()
        )
        
        return self.interceptor.intercept(action)
    
    def get_injection_script(self) -> str:
        """Get JavaScript to inject into web apps"""
        return self.ui_capture.inject_javascript()
    
    def get_stats(self) -> Dict[str, Any]:
        """Get system statistics"""
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        stats = {
            "patterns_learned": cursor.execute("SELECT COUNT(*) FROM patterns").fetchone()[0],
            "corrections_captured": cursor.execute("SELECT COUNT(*) FROM corrections").fetchone()[0],
            "interception_stats": self.interceptor.get_stats()
        }
        
        conn.close()
        
        return stats


# ============= HTTP SERVER FOR CAPTURE =============

def start_capture_server(agent_correct: AgentCorrectV2):
    """Start HTTP server to receive corrections from UI"""
    
    from http.server import HTTPServer, BaseHTTPRequestHandler
    import json
    
    class CaptureHandler(BaseHTTPRequestHandler):
        def do_POST(self):
            if self.path == "/capture":
                content_length = int(self.headers['Content-Length'])
                post_data = self.rfile.read(content_length)
                
                try:
                    correction_data = json.loads(post_data)
                    agent_correct.capture_correction(correction_data)
                    
                    self.send_response(200)
                    self.end_headers()
                    self.wfile.write(b'{"status": "captured"}')
                except Exception as e:
                    self.send_response(500)
                    self.end_headers()
                    self.wfile.write(f'{{"error": "{str(e)}"}}'.encode())
            else:
                self.send_response(404)
                self.end_headers()
        
        def do_OPTIONS(self):
            # Handle CORS preflight
            self.send_response(200)
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'POST, OPTIONS')
            self.send_header('Access-Control-Allow-Headers', 'Content-Type')
            self.end_headers()
        
        def log_message(self, format, *args):
            # Suppress logs
            pass
    
    server = HTTPServer(('localhost', 8888), CaptureHandler)
    
    import threading
    thread = threading.Thread(target=server.serve_forever)
    thread.daemon = True
    thread.start()
    
    print("üåê Capture server running on http://localhost:8888")


# ============= DEMO =============

if __name__ == "__main__":
    
    # Initialize system
    agentcorrect = AgentCorrectV2()
    
    # Start capture server
    start_capture_server(agentcorrect)
    
    print("\n" + "="*60)
    print("AGENTCORRECT V2 - REAL REWORK PREVENTION")
    print("="*60)
    
    # Simulate corrections being captured
    print("\nüìö Simulating captured corrections...")
    
    # Simulate multiple tone corrections
    for i in range(3):
        agentcorrect.capture_correction({
            "timestamp": datetime.now().isoformat(),
            "url": "https://app.zendesk.com/ticket/12345",
            "app": "zendesk",
            "original": "I understand your frustration with this issue.",
            "corrected": "I can help you resolve this quickly.",
            "context": {"user_role": "support_agent"}
        })
    
    # Simulate field additions (idempotency keys)
    for i in range(3):
        agentcorrect.capture_correction({
            "timestamp": datetime.now().isoformat(),
            "url": "https://app.stripe.com/payments",
            "app": "stripe",
            "original": json.dumps({"action": "charge", "amount": 9999, "customer": f"cust_{i}"}),
            "corrected": json.dumps({"action": "charge", "amount": 9999, "customer": f"cust_{i}", "idempotency_key": f"key_{i}"}),
            "context": {"user_role": "developer"}
        })
    
    # Simulate routing corrections
    for i in range(3):
        agentcorrect.capture_correction({
            "timestamp": datetime.now().isoformat(),
            "url": "https://app.servicenow.com/incident",
            "app": "servicenow",
            "original": json.dumps({"category": "password_reset", "team": "network_team", "priority": "low"}),
            "corrected": json.dumps({"category": "password_reset", "team": "help_desk", "priority": "medium"}),
            "context": {"user_role": "it_manager"}
        })
    
    print("\nüß™ Testing interception with learned patterns...")
    
    # Test tone correction
    test_text = agentcorrect.intercept_action(
        "zendesk-ai",
        "draft_reply",
        {"text": "I understand your frustration, but this is how it works."}
    )
    print(f"\n‚úÖ Tone corrected: {test_text.get('text', 'N/A')}")
    
    # Test field addition
    test_payment = agentcorrect.intercept_action(
        "stripe-agent",
        "api_call",
        {"action": "charge", "amount": 5000, "customer": "cust_new"}
    )
    print(f"\n‚úÖ Payment safety: Added idempotency_key: {test_payment.get('idempotency_key', 'N/A')}")
    
    # Test routing correction  
    test_ticket = agentcorrect.intercept_action(
        "servicenow-ai",
        "create_ticket",
        {"category": "password_reset", "team": "network_team", "priority": "low", "description": "User locked out"}
    )
    print(f"\n‚úÖ Routing fixed: Team={test_ticket.get('team')}, Priority={test_ticket.get('priority')}")
    
    # Show statistics
    stats = agentcorrect.get_stats()
    print("\nüìä Statistics:")
    print(f"   Patterns learned: {stats['patterns_learned']}")
    print(f"   Corrections captured: {stats['corrections_captured']}")
    print(f"   Actions corrected: {stats['interception_stats'].get('actions_corrected', 0)}")
    
    print("\nüí° Inject this script into any web app to capture corrections:")
    print("   agentcorrect.get_injection_script()")
    
    print("\n‚ú® AgentCorrect V2 is preventing rework in real-time!")
    print("   Every correction makes every agent better.")